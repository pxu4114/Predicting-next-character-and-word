{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "import bcolz\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "#C:\\Users\\dell\\Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145260\n"
     ]
    }
   ],
   "source": [
    "text_file = open('star-wars.txt').read()\n",
    "print(len(text_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding number of unique characters in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text_file)))\n",
    "print(len(chars)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting unique characters into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {v:i for i,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting index into characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {i:v for i,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting all the characters in the text into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_index = [char_to_index[char] for char in text_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145260"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index of top ten characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 1, 62, 65, 64, 57, 1, 70, 59, 63]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A long time ago in a galaxy far, far away'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index_to_char[i] for i in total_index[:41])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input to RNN and expected output for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num = 7\n",
    "xin = [[total_index[j+i] for j in range(0, len(total_index)-1-pred_num, pred_num)] for i in range(pred_num)]\n",
    "y = [total_index[i+pred_num] for i in range(0, len(total_index)-1-pred_num, pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.stack(xin[i][:-2]) for i in range(pred_num)]\n",
    "Y = np.stack(y[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([25, 70, 65, ..., 64, 60, 57]),\n",
       " array([ 1, 59,  1, ..., 70, 71, 59]),\n",
       " array([62, 63, 59, ..., 71, 69, 64]),\n",
       " array([65, 55, 64, ..., 68, 70, 64]),\n",
       " array([64,  1,  1, ..., 55,  1, 59]),\n",
       " array([57, 51, 51, ...,  8, 52, 64]),\n",
       " array([ 1, 57,  1, ...,  1, 55, 57])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70, 65, 57, 56, 68, 10, 42,  1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 256\n",
    "vocab_size = 78\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, activation='relu'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 7, 42)             3276      \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 78)                20046     \n",
      "=================================================================\n",
      "Total params: 99,866\n",
      "Trainable params: 99,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20749/20749 [==============================] - 3s 137us/step - loss: 3.3225\n",
      "Epoch 2/10\n",
      "20749/20749 [==============================] - 2s 111us/step - loss: 2.6759\n",
      "Epoch 3/10\n",
      "20749/20749 [==============================] - 2s 111us/step - loss: 2.4354\n",
      "Epoch 4/10\n",
      "20749/20749 [==============================] - 2s 109us/step - loss: 2.2779\n",
      "Epoch 5/10\n",
      "20749/20749 [==============================] - 2s 109us/step - loss: 2.1455\n",
      "Epoch 6/10\n",
      "20749/20749 [==============================] - 2s 109us/step - loss: 2.0302\n",
      "Epoch 7/10\n",
      "20749/20749 [==============================] - 2s 110us/step - loss: 1.9239\n",
      "Epoch 8/10\n",
      "20749/20749 [==============================] - 2s 109us/step - loss: 1.8272\n",
      "Epoch 9/10\n",
      "20749/20749 [==============================] - 2s 110us/step - loss: 1.7333\n",
      "Epoch 10/10\n",
      "20749/20749 [==============================] - 2s 109us/step - loss: 1.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62cda2fe48>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.stack(X, 1), Y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First convert input to index\n",
    "#Expand dimension to match the model's output dimension\n",
    "#Predict 8th character....can change this by changing pred_num\n",
    "#Selecting the the character having maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(inp):\n",
    "    index = [char_to_index[i] for i in inp]\n",
    "    arr = np.expand_dims(np.array(index), axis=0)\n",
    "    prediction = model.predict(arr)\n",
    "    return index_to_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('can you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [[total_index[j+i] for j in range(1, len(total_index)-pred_num, pred_num)] for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return = [np.stack(ys[i][:-2]) for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = np.stack(X, 1)\n",
    "Y_model = np.expand_dims(np.stack(Y_return, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 86\n",
    "n_fac = 42\n",
    "hidden_layers = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, return_sequences=True, activation='relu'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 7, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 7, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 7, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20749/20749 [==============================] - 3s 142us/step - loss: 3.0327\n",
      "Epoch 2/10\n",
      "20749/20749 [==============================] - 2s 119us/step - loss: 2.4111\n",
      "Epoch 3/10\n",
      "20749/20749 [==============================] - 2s 119us/step - loss: 2.2523\n",
      "Epoch 4/10\n",
      "20749/20749 [==============================] - 2s 119us/step - loss: 2.1543\n",
      "Epoch 5/10\n",
      "20749/20749 [==============================] - 2s 119us/step - loss: 2.0811\n",
      "Epoch 6/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 2.0251\n",
      "Epoch 7/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.9774\n",
      "Epoch 8/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.9369\n",
      "Epoch 9/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.9033\n",
      "Epoch 10/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62cda29588>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.fit(X_model, Y_model, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.7322\n",
      "Epoch 2/10\n",
      "20749/20749 [==============================] - 2s 114us/step - loss: 1.7141\n",
      "Epoch 3/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.6999\n",
      "Epoch 4/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.6849\n",
      "Epoch 5/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.6706\n",
      "Epoch 6/10\n",
      "20749/20749 [==============================] - 2s 116us/step - loss: 1.6574\n",
      "Epoch 7/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.6463\n",
      "Epoch 8/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.6338\n",
      "Epoch 9/10\n",
      "20749/20749 [==============================] - 2s 115us/step - loss: 1.6246\n",
      "Epoch 10/10\n",
      "20749/20749 [==============================] - 2s 114us/step - loss: 1.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62ccea6128>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_every_char(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "\n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        prediction = return_model.predict(arr)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    \n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nd Che texstoa .mL   '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char('and the boy left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hen cs '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char('this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num, batch_input_shape=(64, 7)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(hidden_layers, activation='tanh', return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide = len(X_model)//64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20736/20736 [==============================] - 6s 288us/step - loss: 1.9103\n",
      "Epoch 2/20\n",
      "20736/20736 [==============================] - 6s 280us/step - loss: 1.8943\n",
      "Epoch 3/20\n",
      "20736/20736 [==============================] - 6s 284us/step - loss: 1.8792\n",
      "Epoch 4/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.8650\n",
      "Epoch 5/20\n",
      "20736/20736 [==============================] - 6s 284us/step - loss: 1.8515\n",
      "Epoch 6/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.8384\n",
      "Epoch 7/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.8259\n",
      "Epoch 8/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.8138\n",
      "Epoch 9/20\n",
      "20736/20736 [==============================] - 6s 284us/step - loss: 1.8023\n",
      "Epoch 10/20\n",
      "20736/20736 [==============================] - 6s 282us/step - loss: 1.7905\n",
      "Epoch 11/20\n",
      "20736/20736 [==============================] - 6s 282us/step - loss: 1.7794\n",
      "Epoch 12/20\n",
      "20736/20736 [==============================] - 6s 281us/step - loss: 1.7690\n",
      "Epoch 13/20\n",
      "20736/20736 [==============================] - 6s 282us/step - loss: 1.7589\n",
      "Epoch 14/20\n",
      "20736/20736 [==============================] - 6s 282us/step - loss: 1.7489\n",
      "Epoch 15/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.7394\n",
      "Epoch 16/20\n",
      "20736/20736 [==============================] - 6s 284us/step - loss: 1.7307\n",
      "Epoch 17/20\n",
      "20736/20736 [==============================] - 6s 283us/step - loss: 1.7218\n",
      "Epoch 18/20\n",
      "20736/20736 [==============================] - 6s 284us/step - loss: 1.7129\n",
      "Epoch 19/20\n",
      "20736/20736 [==============================] - 6s 282us/step - loss: 1.7045\n",
      "Epoch 20/20\n",
      "20736/20736 [==============================] - 6s 279us/step - loss: 1.6968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62cc57cac8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.fit(X_model[:divide], Y_model[:divide], batch_size=64, epochs=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_every_char_LSTM(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        arr = np.resize(arr, (64, 7))\n",
    "        prediction = LSTM_model.predict(arr, batch_size=64)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' en wn '"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char_LSTM('this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
